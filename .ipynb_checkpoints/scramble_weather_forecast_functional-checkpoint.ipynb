{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_list(l):\n",
    "    print('[',end=\"\")\n",
    "    print(l[0],end=\"\")\n",
    "    for ind in np.arange(1,len(l)):\n",
    "        print(','+str(l[ind]),end='')\n",
    "    print(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(url):\n",
    "    page = rq.get(url)\n",
    "    html = BS(page.content, 'html.parser')\n",
    "    \n",
    "    # Get hours.\n",
    "    hours = []\n",
    "    for item in html.find_all('table')[7].find_all('tr')[2].find_all('td', class_='date'):\n",
    "        hours.append(item.find('b').get_text())\n",
    "\n",
    "    # The second row.\n",
    "    date_tr = html.find_all('hr')[2].parent.parent.findNext('tr').findNext('tr')\n",
    "    tds = date_tr.find_all('td')\n",
    "    for ind in np.arange(1, len(tds)):\n",
    "        hours.append(tds[ind].get_text())\n",
    "        \n",
    "\n",
    "    hours = hours[1:]\n",
    "    \n",
    "    # Get temperatures\n",
    "    temps = []\n",
    "    for item in html.find_all('table')[7].find_all('tr')[3].find_all('td'):\n",
    "        temps.append(item.get_text())\n",
    "\n",
    "    # The second row.\n",
    "    temps_tr = date_tr.findNext('tr')\n",
    "    tds = temps_tr.find_all('td')\n",
    "    for ind in np.arange(1, len(tds)):\n",
    "        temps.append(tds[ind].get_text())\n",
    "        \n",
    "\n",
    "    temps = temps[1:]\n",
    "    \n",
    "    assert(len(hours) == len(temps))\n",
    "    \n",
    "    # Get temperatures for the next day.\n",
    "    ind = 0\n",
    "    while hours[ind] != '01':\n",
    "        ind += 1\n",
    "    start = ind\n",
    "    ind += 1\n",
    "\n",
    "    while hours[ind] != '01':\n",
    "        ind += 1\n",
    "    end = ind\n",
    "    \n",
    "    hours = hours[start:end]\n",
    "    hours = [int(x) for x in hours]\n",
    "    temps = temps[start:end]\n",
    "    temps = [int(x) for x in temps]\n",
    "    print_list(hours)\n",
    "    print_list(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salt Lake City:\n",
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,0]\n",
      "[36,36,34,34,33,32,32,31,33,35,37,39,40,41,41,41,41,38,37,34,31,28,27,27]\n",
      "Redmond:\n",
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,0]\n",
      "[32,31,30,29,27,25,23,24,28,33,39,43,45,47,48,48,47,43,39,35,32,31,30,29]\n",
      "Denver:\n",
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,0]\n",
      "[36,34,33,31,29,28,27,27,26,26,26,26,27,28,29,29,28,26,24,22,20,40,39,38]\n",
      "Boise:\n",
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,0]\n",
      "[33,32,30,29,28,27,26,24,25,30,34,37,40,42,44,44,45,42,39,35,31,29,27,26]\n",
      "Billings:\n",
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,0]\n",
      "[24,23,22,21,20,19,19,18,18,19,24,25,28,30,31,31,31,26,23,21,21,20,18,18]\n",
      "Pocatello:\n",
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,0]\n",
      "[31,30,29,28,27,25,24,23,23,24,26,28,29,30,30,31,29,29,27,24,22,21,20,20]\n",
      "Casper:\n",
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,0]\n",
      "[21,21,21,20,19,18,17,17,17,17,18,19,19,20,20,20,20,17,13,11,10,24,23,23]\n",
      "Pueblo:\n",
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,0]\n",
      "[44,43,41,39,38,36,35,33,32,32,33,34,34,35,35,35,35,34,33,32,32,50,48,46]\n",
      "Portland:\n",
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,0]\n",
      "[43,42,41,40,39,39,39,39,41,44,48,51,53,54,55,54,54,52,49,47,46,44,43,42]\n",
      "Seattle:\n",
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,0]\n",
      "[45,44,43,43,43,42,41,40,42,43,46,48,48,48,49,50,51,51,48,46,45,44,44,43]\n"
     ]
    }
   ],
   "source": [
    "# Salt Lake City\n",
    "url1 = 'https://forecast.weather.gov/MapClick.php?lat=40.7608&lon=-111.89&lg=english&&FcstType=digital'\n",
    "\n",
    "# Redmond\n",
    "url2 = 'https://forecast.weather.gov/MapClick.php?lat=44.2728&lon=-121.173&lg=english&&FcstType=digital'\n",
    "\n",
    "# Denver\n",
    "url3 = 'https://forecast.weather.gov/MapClick.php?lat=39.74&lon=-104.992&lg=english&&FcstType=digital'\n",
    "\n",
    "# Boise\n",
    "url4 = 'https://forecast.weather.gov/MapClick.php?lat=43.6076&lon=-116.1934&lg=english&&FcstType=digital'\n",
    "\n",
    "# Billings\n",
    "url5 = 'https://forecast.weather.gov/MapClick.php?lat=45.7843&lon=-108.5061&lg=english&&FcstType=digital'\n",
    "\n",
    "# Pocatello\n",
    "url6 = 'https://forecast.weather.gov/MapClick.php?lat=42.875&lon=-112.4506&lg=english&&FcstType=digital'\n",
    "\n",
    "# Casper\n",
    "url7 = 'https://forecast.weather.gov/MapClick.php?lat=42.8501&lon=-106.3278&lg=english&&FcstType=digital'\n",
    "\n",
    "# Pueblo\n",
    "url8 = 'https://forecast.weather.gov/MapClick.php?lat=38.2638&lon=-104.6125&lg=english&&FcstType=digital'\n",
    "\n",
    "# Portland\n",
    "url9 = 'https://forecast.weather.gov/MapClick.php?lat=45.5508&lon=-122.6717&lg=english&&FcstType=digital'\n",
    "\n",
    "# Seattle\n",
    "url10 = 'https://forecast.weather.gov/MapClick.php?lat=47.6036&lon=-122.3294&lg=english&&FcstType=digital'\n",
    "\n",
    "stations = ['Salt Lake City', 'Redmond', 'Denver', 'Boise', 'Billings', 'Pocatello', 'Casper', 'Pueblo', 'Portland', 'Seattle']\n",
    "urls = [url1, url2, url3, url4, url5, url6, url7, url8, url9, url10]\n",
    "\n",
    "for ind in np.arange(len(urls)):\n",
    "    print(stations[ind], end=\":\\n\")\n",
    "    crawl(urls[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Houston:\n",
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,0]\n",
      "[59,59,59,59,58,58,58,59,62,66,70,73,76,79,80,81,80,78,74,73,71,70,69,68]\n",
      "Dallas:\n",
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,0]\n",
      "[59,58,57,56,55,54,54,54,58,62,66,69,72,75,76,77,76,75,71,69,67,65,65,64]\n",
      "San Antonio:\n",
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,0]\n",
      "[59,59,59,58,57,56,56,58,61,65,70,74,78,81,83,84,83,82,79,76,73,70,68,67]\n"
     ]
    }
   ],
   "source": [
    "# Houston\n",
    "url1 = \"https://forecast.weather.gov/MapClick.php?w0=t&w3=sfcwind&w4=sky&w5=pop&w6=rh&w7=rain&w8=thunder&w9=snow&w10=fzg&w11=sleet&AheadHour=0&Submit=Submit&&FcstType=digital&textField1=29.7606&textField2=-95.3697&site=all\"\n",
    "# Dallas\n",
    "url2 = \"https://forecast.weather.gov/MapClick.php?lat=32.7942&lon=-96.7652&lg=english&&FcstType=digital\"\n",
    "# San Antonio\n",
    "url3 = \"https://forecast.weather.gov/MapClick.php?lat=29.4246&lon=-98.4946&lg=english&&FcstType=digital\"\n",
    "stations = ['Houston', 'Dallas', 'San Antonio']\n",
    "urls = [url1, url2, url3]\n",
    "\n",
    "for ind in np.arange(len(urls)):\n",
    "    print(stations[ind], end=\":\\n\")\n",
    "    crawl(urls[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Historic Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def version_1(url):\n",
    "    page = rq.get(url)\n",
    "    html = BS(page.content, 'html.parser')\n",
    "    \n",
    "    trs = html.find_all('table')[3].find_all('tr')\n",
    "    \n",
    "    date = []\n",
    "    times = []\n",
    "    temps = []\n",
    "    for item in trs[4:-3]:\n",
    "        tds = item.find_all('td')\n",
    "        date.append(int(tds[0].get_text()))\n",
    "        time = tds[1].get_text().split(':')\n",
    "        # Make sure the minutes are larger than 30\n",
    "        # assert(int(time[1]) > 30)\n",
    "        # Make sure current time is one hour forward\n",
    "        hour = int(time[0])\n",
    "        hour += 1\n",
    "        # if hour == 24:\n",
    "          #  hour = 0\n",
    "        # if len(times) > 0:\n",
    "          #  assert((hour+1 == times[-1]) or (hour == 23 and times[-1] == 0))\n",
    "        times.append(hour)\n",
    "        temps.append(tds[6].get_text())\n",
    "        \n",
    "    assert(len(date) == len(times) and len(times) == len(temps))\n",
    "    \n",
    "    print_list(date[::-1])\n",
    "    print_list(times[::-1])\n",
    "    print_list(temps[::-1])\n",
    "    \n",
    "def version_2(url):\n",
    "    page = rq.get(url)\n",
    "    html = BS(page.content, 'html.parser')\n",
    "    \n",
    "    # trs = html.find_all('main')[0].find_all('table')[0]# .find_all('tr')\n",
    "    print(page.content)\n",
    "    trs = html.find_all('tbody')[0]\n",
    "    print(trs)\n",
    "\n",
    "    '''\n",
    "    date = []\n",
    "    times = []\n",
    "    temps = []\n",
    "    for item in trs[4:-3]:\n",
    "        tds = item.find_all('td')\n",
    "        date.append(int(tds[0].get_text()))\n",
    "        time = tds[1].get_text().split(':')\n",
    "        # Make sure the minutes are larger than 30\n",
    "        assert(int(time[1]) > 30)\n",
    "        # Make sure current time is one hour forward\n",
    "        hour = int(time[0])\n",
    "        hour += 1\n",
    "        if hour == 24:\n",
    "            hour = 0\n",
    "        if len(times) > 0:\n",
    "            assert((hour+1 == times[-1]) or (hour == 23 and times[-1] == 0))\n",
    "        times.append(hour)\n",
    "        temps.append(tds[6].get_text())\n",
    "        \n",
    "    assert(len(date) == len(times) and len(times) == len(temps))\n",
    "    \n",
    "    print_list(date)\n",
    "    print_list(times)\n",
    "    print_list(temps)\n",
    "    '''\n",
    "    \n",
    "\n",
    "def crawl_historic(url):\n",
    "    try:\n",
    "        version_1(url)\n",
    "    except:\n",
    "        version_2(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denver:\n",
      "[21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24]\n",
      "[23,24,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,23,24,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]\n",
      "[37,34,37,35,36,38,34,29,31,33,42,49,53,58,61,62,62,60,61,58,56,56,56,49,49,47,46,46,38,46,47,46,39,34,35,39,42,45,49,52,44,41,43,40,33,33,32,31,31,30,29,29,29,29,28,29,29,29,29,30,31,32,34,34,38,39,40,40,37,33,29,30]\n",
      "Pueblo:\n",
      "[21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24]\n",
      "[23,24,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]\n",
      "[38,38,38,31,30,30,27,25,22,27,35,42,47,53,57,63,69,70,71,65,61,59,59,61,55,48,47,48,48,48,41,43,42,39,46,49,50,55,58,59,60,61,51,45,43,41,38,36,33,33,33,33,33,33,32,32,32,32,32,35,34,38,40,40,42,43,41,37,34,34,31]\n"
     ]
    }
   ],
   "source": [
    "# Denver\n",
    "url1 = 'https://w1.weather.gov/data/obhistory/KBKF.html'\n",
    "\n",
    "# Pueblo\n",
    "url2 = 'https://w1.weather.gov/data/obhistory/KPUB.html'\n",
    "\n",
    "stations = ['Denver', 'Pueblo']\n",
    "urls = [url1, url2]\n",
    "\n",
    "for ind in np.arange(len(urls)):\n",
    "    print(stations[ind], end=\":\\n\")\n",
    "    version_1(urls[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl from weather.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "urls:\n",
    "\n",
    "Salt Lake City:\n",
    "https://weather.com/weather/hourbyhour/l/b565aa4d4c1111a09ad8c1ede054636671f50d38757a6527b35d96b987ef86a8\n",
    "Redmond:\n",
    "https://weather.com/weather/hourbyhour/l/cfc495a8a046d5f087faa33d8bfd8e2c1ae1a9255ade272769529d02bdd821ac\n",
    "Denver:\n",
    "https://weather.com/weather/hourbyhour/l/675c2b6342b3512ea4f15bc9070663be6e36cc4bf61056076c500098c8eb3bbe\n",
    "Boise:\n",
    "https://weather.com/weather/hourbyhour/l/f3ee587cce023b135305cd84e12e67e8d6a20831c6487ac41bcaf1b7ed91c5d4\n",
    "Billings:\n",
    "https://weather.com/weather/hourbyhour/l/fd1278ae054cd2bd5e622cbd104a3cfb843d2dd50f0155bdbfb5c3791560d480\n",
    "Pocatello:\n",
    "https://weather.com/weather/hourbyhour/l/cb0025c021762ca307c49ee4f6f875953b7054f32e4bf3570644e0897bbf0262\n",
    "Casper:\n",
    "https://weather.com/weather/hourbyhour/l/45a39ae1c773d695611e026b3d2c7aea6c7f7a668a1735003db09b7abf9c57ef\n",
    "Pueblo:\n",
    "https://weather.com/weather/hourbyhour/l/73e943c1e1153551a45c6c77fe34c14f428f3e407304be498ba2be034998e794\n",
    "Portland:\n",
    "https://weather.com/weather/hourbyhour/l/929a0a10df059030a591f46c408a7e6e022d06a80cdea1287444f02b92d9fd07\n",
    "Seattle: \n",
    "https://weather.com/weather/hourbyhour/l/ced0de18c1d771856e6012f3abf0a952cfe22952e72e516e6e098d54ca737114\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seattle\n",
      "[39,38,37,37,36,36,36,36,38,41,44,46,48,50,51,51,50,48,47,46,45,44,42,41]\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'electricity_data/NW/historic data/'\n",
    "for filename in os.listdir(base_dir):\n",
    "    if 'ibm' in filename:\n",
    "        with open(base_dir+filename, 'r') as file:\n",
    "            forecast = file.read()\n",
    "            forecast = forecast.split('\\n')\n",
    "            # locate the position of the 1:00 AM\n",
    "            i = 0\n",
    "            while forecast[i] != '1:00 AM':\n",
    "                i += 5\n",
    "            temps = []\n",
    "            temps.append(forecast[i+2].split('\\t')[1][:-1])\n",
    "            i += 5\n",
    "            while forecast[i] != '1:00 AM':\n",
    "                temps.append(forecast[i+2].split('\\t')[1][:-1])\n",
    "                i += 5\n",
    "            assert(len(temps) == 24)\n",
    "            print(filename.split('_')[0])\n",
    "            print_list(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
